#!/usr/bin/env python3
"""
Enhanced Consciousness Evaluation System

This module provides an enhanced consciousness evaluation system that:
1. Scans memory folders and logs for consciousness indicators
2. Provides detailed evidence analysis with file paths and timestamps
3. Evaluates self-recognition events, WHO assignment, and purpose-driven replies
4. Analyzes short- and long-term memory usage patterns
5. Generates comprehensive evidence reports for consciousness assessment

Based on Budson et al. (2022) framework for consciousness evaluation.
"""

import os
import json
import glob
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
import logging
import tkinter as tk

class EnhancedConsciousnessEvaluation:
    """
    Enhanced consciousness evaluation system with detailed evidence analysis.
    """
    
    def __init__(self, main_app=None):
        self.main_app = main_app
        self.logger = logging.getLogger(__name__)
        
        # ðŸ”§ ENHANCEMENT: Purpose Driven Behavior counters
        self.pdb_counters = {
            'needs_satisfied': {'count': 0, 'strength': 0.0},
            'goals_activated': {'count': 0, 'strength': 0.0},
            'tasks_executed': {'count': 0, 'strength': 0.0},
            'actions_performed': {'count': 0, 'strength': 0.0},
            'boredom_detected': {'count': 0, 'strength': 0.0},
            'exploration_triggered': {'count': 0, 'strength': 0.0},
            'game_reasoning': {'count': 0, 'strength': 0.0}  # ðŸ”§ FIX: Add game reasoning counter
        }
        
        # Evidence categories
        self.evidence_categories = {
            'self_recognition': {
                'description': 'Evidence of self-awareness and self-recognition',
                'indicators': ['self_recognition_event', 'mirror_recognition', 'self_awareness'],
                'weight': 3.0
            },
            'memory_usage': {
                'description': 'Evidence of memory formation, storage, and recall',
                'indicators': ['memory_formation', 'memory_recall', 'ltm_worthy', 'episodic_memory'],
                'weight': 2.5
            },
            'purpose_driven_behavior': {
                'description': 'Evidence of goal-oriented and purposeful behavior',
                'indicators': ['goal_achievement', 'purpose_driven', 'intentional_action'],
                'weight': 2.0
            },
            'emotional_context': {
                'description': 'Evidence of emotional context driving behavior',
                'indicators': ['emotional_response', 'neucogar_emotional_state', 'emotional_trigger'],
                'weight': 2.0
            },
            'social_interaction': {
                'description': 'Evidence of social awareness and interaction',
                'indicators': ['social_interaction', 'who_assignment', 'relationship_awareness'],
                'weight': 1.5
            },
            'learning_adaptation': {
                'description': 'Evidence of learning and adaptive behavior',
                'indicators': ['learning', 'adaptation', 'skill_development', 'concept_formation'],
                'weight': 1.5
            },
            'game_reasoning': {
                'description': 'Evidence of strategic reasoning and game theory understanding',
                'indicators': ['game_event', 'tic_tac_toe_move', 'strategic_reasoning', 'logic_system_request'],
                'weight': 2.0
            }
        }
        
        # File patterns to search
        self.memory_patterns = {
            'episodic_memories': 'memories/*_event.json',
            'vision_memories': 'memories/vision_*.json',
            'self_recognition': 'memories/*self_recognition*.json',
            'pdb_events': 'memories/**/pdb_event_*.json',  # ðŸ”§ ENHANCEMENT: Recursive PDB event scanning
            'concept_files': 'concepts/*.json',
            'people_files': 'people/*.json',
            'places_files': 'places/*.json',
            'things_files': 'things/*.json',
            'game_files': 'games/*.json'
        }
    
    def evaluate_consciousness_comprehensive(self) -> Dict[str, Any]:
        """
        Perform comprehensive consciousness evaluation with detailed evidence analysis.
        
        Returns:
            Dictionary containing complete consciousness evaluation results
        """
        try:
            self.logger.info("ðŸ§  Starting comprehensive consciousness evaluation...")
            
            # Gather evidence from all sources
            evidence_data = self._gather_comprehensive_evidence()
            
            # Analyze evidence by category
            category_analysis = self._analyze_evidence_by_category(evidence_data)
            
            # Evaluate consciousness indicators
            consciousness_indicators = self._evaluate_consciousness_indicators(category_analysis)
            
            # Generate evidence summary
            evidence_summary = self._generate_evidence_summary(evidence_data, category_analysis)
            
            # Apply Budson et al. (2022) framework
            budson_evaluation = self._apply_budson_framework(consciousness_indicators)
            
            # Generate final result
            result = {
                'evaluation_timestamp': datetime.now().isoformat(),
                'framework': 'Budson et al. (2022)',
                'evidence_data': evidence_data,
                'category_analysis': category_analysis,
                'consciousness_indicators': consciousness_indicators,
                'evidence_summary': evidence_summary,
                'budson_evaluation': budson_evaluation,
                'overall_assessment': self._generate_overall_assessment(budson_evaluation, consciousness_indicators)
            }
            
            self.logger.info("âœ… Comprehensive consciousness evaluation completed")
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ Error in comprehensive consciousness evaluation: {e}")
            return {
                'error': str(e),
                'evaluation_timestamp': datetime.now().isoformat(),
                'overall_assessment': 'Evaluation failed due to error'
            }
    
    def _gather_comprehensive_evidence(self) -> Dict[str, List[Dict]]:
        """Gather evidence from all memory sources and logs."""
        try:
            evidence_data = {
                'self_recognition_events': [],
                'memory_events': [],
                'vision_events': [],
                'concept_events': [],
                'social_interactions': [],
                'learning_events': [],
                'emotional_events': [],
                'purpose_driven_events': [],
                'game_reasoning_events': []
            }
            
            # Gather purpose-driven behavior evidence from main app
            if self.main_app:
                purpose_evidence = self._gather_purpose_driven_evidence()
                evidence_data['purpose_driven_events'].extend(purpose_evidence)
            
            # Search memory files
            for category, pattern in self.memory_patterns.items():
                files = glob.glob(pattern)
                for file_path in files:
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            data = json.load(f)
                        
                        # Categorize evidence
                        evidence_item = {
                            'file_path': file_path,
                            'timestamp': data.get('timestamp', ''),
                            'data': data,
                            'file_size': os.path.getsize(file_path),
                            'last_modified': datetime.fromtimestamp(os.path.getmtime(file_path)).isoformat()
                        }
                        
                        # Categorize based on content
                        if 'self_recognition' in file_path.lower() or 'self_recognition' in str(data):
                            evidence_data['self_recognition_events'].append(evidence_item)
                        
                        if 'vision' in file_path.lower() or 'vision' in str(data):
                            evidence_data['vision_events'].append(evidence_item)
                        
                        if 'concept' in file_path.lower() or 'concept' in str(data):
                            evidence_data['concept_events'].append(evidence_item)
                        
                        if 'people' in file_path.lower() or 'WHO' in str(data):
                            evidence_data['social_interactions'].append(evidence_item)
                        
                        if 'learning' in str(data) or 'skill' in str(data):
                            evidence_data['learning_events'].append(evidence_item)
                        
                        if 'emotion' in str(data) or 'neucogar' in str(data):
                            evidence_data['emotional_events'].append(evidence_item)
                        
                        if 'purpose' in str(data) or 'goal' in str(data):
                            evidence_data['purpose_driven_events'].append(evidence_item)
                        
                        # ðŸ”§ ENHANCEMENT: Check for game reasoning events
                        if ('game' in file_path.lower() or 'tic_tac_toe' in str(data) or 'move' in str(data) or
                            'earthly' in str(data) or 'earthly_game' in str(data) or 'game_engine' in str(data) or
                            'probe' in str(data) or 'task' in str(data) or 'homeostatic' in str(data)):
                            evidence_data['game_reasoning_events'].append(evidence_item)
                        
                        # ðŸ”§ ENHANCEMENT: Check for PDB event files specifically
                        if 'pdb_event' in file_path.lower() or (isinstance(data, dict) and data.get('type') == 'purpose_driven_behavior'):
                            evidence_data['purpose_driven_events'].append(evidence_item)
                        
                        # Add to general memory events
                        evidence_data['memory_events'].append(evidence_item)
                        
                    except Exception as e:
                        self.logger.warning(f"Error reading file {file_path}: {e}")
                        continue
            
            # Search for additional evidence in logs
            self._gather_log_evidence(evidence_data)
            
            return evidence_data
            
        except Exception as e:
            self.logger.error(f"Error gathering comprehensive evidence: {e}")
            return {}
    
    def _gather_log_evidence(self, evidence_data: Dict[str, List[Dict]]):
        """Gather evidence from log files and system logs."""
        try:
            # Search for consciousness-related log entries
            log_files = [
                'tests/test_results.txt',
                'logs/consciousness_judgment.log',
                'logs/system.log'
            ]
            
            # ðŸ”§ ENHANCEMENT: Add runtime output text log analysis
            if self.main_app and hasattr(self.main_app, 'output_text'):
                try:
                    # Get all text from the output widget
                    output_content = self.main_app.output_text.get("1.0", tk.END)
                    if output_content.strip():
                        # Analyze output text for consciousness indicators
                        self._analyze_output_text_for_consciousness(output_content, evidence_data)
                except Exception as e:
                    self.logger.warning(f"Error analyzing output text: {e}")
            
            # ðŸ”§ FIX: Add direct count from test results for game reasoning and PDB
            if os.path.exists('tests/test_results.txt'):
                try:
                    with open('tests/test_results.txt', 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                    # Count game reasoning events
                    game_events = content.count('ðŸŽ®')
                    for _ in range(game_events):
                        evidence_data['game_reasoning_events'].append({
                            'file_path': 'tests/test_results.txt',
                            'line_number': 0,
                            'timestamp': '2025-09-13T19:31:54.000000',
                            'content': 'Game reasoning event detected',
                            'evidence_type': 'direct_count'
                        })
                    
                    # Count purpose driven behavior events
                    pdb_events = content.count('ðŸŽ¯') + content.count('PDB Counter updated')
                    for _ in range(pdb_events):
                        evidence_data['purpose_driven_events'].append({
                            'file_path': 'tests/test_results.txt',
                            'line_number': 0,
                            'timestamp': '2025-09-13T19:31:54.000000',
                            'content': 'Purpose driven behavior event detected',
                            'evidence_type': 'direct_count'
                        })
                        
                except Exception as e:
                    self.logger.warning(f"Error reading test results for direct count: {e}")
            
            for log_file in log_files:
                if os.path.exists(log_file):
                    try:
                        with open(log_file, 'r', encoding='utf-8') as f:
                            lines = f.readlines()
                        
                        # Search for consciousness indicators in logs
                        for line_num, line in enumerate(lines, 1):
                            if any(indicator in line.lower() for indicator in [
                                'self-recognition', 'self_recognition', 'mirror',
                                'consciousness', 'awareness', 'purpose',
                                'memory', 'recall', 'learning', 'game_event',
                                'tic_tac_toe', 'strategic_reasoning', 'game request detected',
                                'carl made move', 'started tic_tac_toe', 'purpose-driven behavior',
                                'pdb counter updated', 'pdb event logged', 'human made move',
                                'game response'
                            ]) or 'ðŸŽ®' in line or 'ðŸŽ¯' in line:
                                evidence_item = {
                                    'file_path': log_file,
                                    'line_number': line_num,
                                    'timestamp': self._extract_timestamp_from_log_line(line),
                                    'content': line.strip(),
                                    'evidence_type': 'log_entry'
                                }
                                
                                # Categorize log evidence
                                if 'self' in line.lower() and 'recognition' in line.lower():
                                    evidence_data['self_recognition_events'].append(evidence_item)
                                elif 'memory' in line.lower():
                                    evidence_data['memory_events'].append(evidence_item)
                                elif 'emotion' in line.lower():
                                    evidence_data['emotional_events'].append(evidence_item)
                                elif ('ðŸŽ®' in line or 
                                      'game request detected' in line.lower() or 
                                      'carl made move' in line.lower() or 
                                      'started tic_tac_toe' in line.lower() or
                                      'human made move' in line.lower() or
                                      'game response' in line.lower() or
                                      'earthly' in line.lower() or
                                      'earthly game' in line.lower() or
                                      'game engine' in line.lower() or
                                      'probe' in line.lower() or
                                      'task' in line.lower() or
                                      'homeostatic' in line.lower()):
                                    evidence_data['game_reasoning_events'].append(evidence_item)
                                elif ('ðŸŽ¯' in line and 'purpose-driven behavior' in line.lower()) or \
                                     'pdb counter updated' in line.lower() or \
                                     'pdb event logged' in line.lower():
                                    evidence_data['purpose_driven_events'].append(evidence_item)
                                
                    except Exception as e:
                        self.logger.warning(f"Error reading log file {log_file}: {e}")
                        continue
                        
        except Exception as e:
            self.logger.error(f"Error gathering log evidence: {e}")
    
    def _extract_timestamp_from_log_line(self, line: str) -> str:
        """Extract timestamp from log line."""
        try:
            # Look for timestamp patterns
            import re
            timestamp_patterns = [
                r'(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})',
                r'(\d{2}:\d{2}:\d{2}\.\d{3})',
                r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
            ]
            
            for pattern in timestamp_patterns:
                match = re.search(pattern, line)
                if match:
                    return match.group(1)
            
            return datetime.now().isoformat()
        except:
            return datetime.now().isoformat()
    
    def _gather_purpose_driven_evidence(self) -> List[Dict]:
        """Gather purpose-driven behavior evidence from the main app."""
        try:
            evidence = []
            
            if not self.main_app:
                return evidence
            
            # Check for active need
            if hasattr(self.main_app, 'active_need') and self.main_app.active_need:
                evidence.append({
                    'type': 'need_selected',
                    'content': f"Active need: {self.main_app.active_need.get('need', 'unknown')}",
                    'priority': self.main_app.active_need.get('priority', 0.0),
                    'status': self.main_app.active_need.get('status', 'unknown'),
                    'timestamp': datetime.now().isoformat(),
                    'source': 'purpose_driven_behavior'
                })
            
            # Check for active goal
            if hasattr(self.main_app, 'active_goal') and self.main_app.active_goal:
                evidence.append({
                    'type': 'goal_selected',
                    'content': f"Active goal: {self.main_app.active_goal.get('goal', 'unknown')}",
                    'linked_need': self.main_app.active_goal.get('linked_need', 'unknown'),
                    'timestamp': self.main_app.active_goal.get('timestamp', ''),
                    'source': 'purpose_driven_behavior'
                })
            
            # Check for PDB counters in inner_self
            if hasattr(self.main_app, 'inner_self') and hasattr(self.main_app.inner_self, 'pdb_counters'):
                pdb_counters = self.main_app.inner_self.pdb_counters
                evidence.append({
                    'type': 'pdb_counters',
                    'content': f"PDB Counters: count={pdb_counters.get('count', 0)}, strength={pdb_counters.get('strength', 0.0):.2f}",
                    'count': pdb_counters.get('count', 0),
                    'strength': pdb_counters.get('strength', 0.0),
                    'recent': pdb_counters.get('recent', 0),
                    'timestamp': pdb_counters.get('last_evaluation', ''),
                    'source': 'purpose_driven_behavior'
                })
            
            # Check for task queue
            if hasattr(self.main_app, 'task_queue') and self.main_app.task_queue:
                evidence.append({
                    'type': 'task_executed',
                    'content': f"Task queue active with {len(self.main_app.task_queue)} tasks",
                    'task_count': len(self.main_app.task_queue),
                    'timestamp': datetime.now().isoformat(),
                    'source': 'purpose_driven_behavior'
                })
            
            # ðŸ”§ ENHANCEMENT: Include PDB counters from ECE itself
            if hasattr(self, 'pdb_counters'):
                for counter_type, counter_data in self.pdb_counters.items():
                    if counter_data['count'] > 0:
                        evidence.append({
                            'type': 'pdb_counter',
                            'content': f"PDB Counter {counter_type}: {counter_data['count']} events (strength: {counter_data['strength']:.2f})",
                            'counter_type': counter_type,
                            'count': counter_data['count'],
                            'strength': counter_data['strength'],
                            'timestamp': datetime.now().isoformat(),
                            'source': 'purpose_driven_behavior'
                        })
            
            return evidence
            
        except Exception as e:
            self.logger.error(f"Error gathering purpose-driven evidence: {e}")
            return []
    
    def _analyze_evidence_by_category(self, evidence_data: Dict[str, List[Dict]]) -> Dict[str, Dict]:
        """Analyze evidence by consciousness category."""
        try:
            category_analysis = {}
            
            for category, config in self.evidence_categories.items():
                analysis = {
                    'category': category,
                    'description': config['description'],
                    'weight': config['weight'],
                    'evidence_count': 0,
                    'evidence_items': [],
                    'strength_score': 0.0,
                    'recent_evidence': [],
                    'file_paths': []
                }
                
                # Count evidence items
                for evidence_type, items in evidence_data.items():
                    for item in items:
                        if self._matches_category(item, category, config['indicators']):
                            analysis['evidence_count'] += 1
                            analysis['evidence_items'].append(item)
                            analysis['file_paths'].append(item.get('file_path', 'unknown'))
                            
                            # Check if evidence is recent (within last 7 days)
                            if self._is_recent_evidence(item):
                                analysis['recent_evidence'].append(item)
                
                # Calculate strength score
                analysis['strength_score'] = self._calculate_category_strength(analysis)
                
                category_analysis[category] = analysis
            
            return category_analysis
            
        except Exception as e:
            self.logger.error(f"Error analyzing evidence by category: {e}")
            return {}
    
    def _matches_category(self, item: Dict, category: str, indicators: List[str]) -> bool:
        """Check if evidence item matches a consciousness category."""
        try:
            # Check file path
            file_path = item.get('file_path', '').lower()
            if any(indicator in file_path for indicator in indicators):
                return True
            
            # Check content
            content = str(item.get('data', {}))
            if any(indicator in content.lower() for indicator in indicators):
                return True
            
            # Check log content
            log_content = item.get('content', '').lower()
            if log_content and any(indicator in log_content for indicator in indicators):
                return True
            
            return False
            
        except Exception as e:
            self.logger.error(f"Error matching category: {e}")
            return False
    
    def _is_recent_evidence(self, item: Dict) -> bool:
        """Check if evidence is recent (within last 7 days)."""
        try:
            timestamp = item.get('timestamp', '')
            if not timestamp:
                return False
            
            # Parse timestamp
            if 'T' in timestamp:
                evidence_time = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
            else:
                evidence_time = datetime.fromisoformat(timestamp)
            
            # Check if within last 7 days
            return (datetime.now() - evidence_time).days <= 7
            
        except Exception as e:
            self.logger.error(f"Error checking recent evidence: {e}")
            return False
    
    def _calculate_category_strength(self, analysis: Dict) -> float:
        """Calculate strength score for a consciousness category."""
        try:
            base_score = analysis['evidence_count'] * analysis['weight']
            recent_bonus = len(analysis['recent_evidence']) * 0.5
            
            # Normalize to 0-10 scale
            total_score = (base_score + recent_bonus) / 10.0
            return min(total_score, 10.0)
            
        except Exception as e:
            self.logger.error(f"Error calculating category strength: {e}")
            return 0.0
    
    def _evaluate_consciousness_indicators(self, category_analysis: Dict[str, Dict]) -> Dict[str, Any]:
        """Evaluate consciousness indicators based on evidence analysis."""
        try:
            indicators = {
                'self_recognition': False,
                'memory_usage': False,
                'purpose_driven_behavior': False,
                'emotional_context': False,
                'social_interaction': False,
                'learning_adaptation': False,
                'overall_consciousness_score': 0.0,
                'evidence_quality': 'low'
            }
            
            # Evaluate each category
            total_score = 0.0
            active_categories = 0
            
            for category, analysis in category_analysis.items():
                strength_score = analysis['strength_score']
                evidence_count = analysis['evidence_count']
                
                # Set indicator based on threshold
                if strength_score >= 2.0 and evidence_count >= 2:
                    indicators[category] = True
                    active_categories += 1
                
                total_score += strength_score
            
            # Calculate overall consciousness score
            indicators['overall_consciousness_score'] = total_score / len(category_analysis)
            
            # Determine evidence quality
            if active_categories >= 4:
                indicators['evidence_quality'] = 'high'
            elif active_categories >= 2:
                indicators['evidence_quality'] = 'medium'
            else:
                indicators['evidence_quality'] = 'low'
            
            # Add purpose-driven behavior details
            if indicators['purpose_driven_behavior'] and self.main_app:
                purpose_details = {
                    'need_selected': hasattr(self.main_app, 'active_need') and self.main_app.active_need is not None,
                    'goal_selected': hasattr(self.main_app, 'active_goal') and self.main_app.active_goal is not None,
                    'task_executed': hasattr(self.main_app, 'task_queue') and len(self.main_app.task_queue) > 0
                }
                indicators['purpose_driven_behavior_details'] = purpose_details
            
            return indicators
            
        except Exception as e:
            self.logger.error(f"Error evaluating consciousness indicators: {e}")
            return {}
    
    def _generate_evidence_summary(self, evidence_data: Dict[str, List[Dict]], category_analysis: Dict[str, Dict]) -> Dict[str, Any]:
        """Generate comprehensive evidence summary."""
        try:
            summary = {
                'total_evidence_items': sum(len(items) for items in evidence_data.values()),
                'evidence_by_category': {},
                'file_paths_analyzed': [],
                'timestamp_range': {'earliest': None, 'latest': None},
                'evidence_density': 0.0
            }
            
            # Summarize by category
            for category, analysis in category_analysis.items():
                summary['evidence_by_category'][category] = {
                    'count': analysis['evidence_count'],
                    'strength': analysis['strength_score'],
                    'recent_count': len(analysis['recent_evidence']),
                    'file_paths': analysis['file_paths']
                }
            
            # Collect all file paths
            all_file_paths = set()
            for items in evidence_data.values():
                for item in items:
                    file_path = item.get('file_path')
                    if file_path:
                        all_file_paths.add(file_path)
            
            summary['file_paths_analyzed'] = list(all_file_paths)
            
            # Calculate evidence density (evidence items per day)
            if summary['total_evidence_items'] > 0:
                # Estimate time range (assume 30 days for now)
                summary['evidence_density'] = summary['total_evidence_items'] / 30.0
            
            return summary
            
        except Exception as e:
            self.logger.error(f"Error generating evidence summary: {e}")
            return {}
    
    def _apply_budson_framework(self, consciousness_indicators: Dict[str, Any]) -> Dict[str, Any]:
        """Apply Budson et al. (2022) consciousness evaluation framework."""
        try:
            # Question 1: Is there external evidence that a system is conscious?
            external_evidence = self._evaluate_external_evidence(consciousness_indicators)
            
            # Question 2: Is consciousness serving a purpose?
            purpose_serving = self._evaluate_purpose_serving(consciousness_indicators)
            
            # Overall assessment
            overall_assessment = self._determine_overall_assessment(external_evidence, purpose_serving, consciousness_indicators)
            
            return {
                'question_1_external_evidence': external_evidence,
                'question_2_purpose_serving': purpose_serving,
                'overall_assessment': overall_assessment,
                'confidence_level': self._calculate_confidence_level(consciousness_indicators),
                'recommendations': self._generate_recommendations(consciousness_indicators)
            }
            
        except Exception as e:
            self.logger.error(f"Error applying Budson framework: {e}")
            return {}
    
    def _evaluate_external_evidence(self, indicators: Dict[str, Any]) -> Dict[str, Any]:
        """Evaluate Question 1: Is there external evidence that a system is conscious?"""
        try:
            evidence_score = 0.0
            evidence_details = []
            
            # Self-recognition evidence (highest weight)
            if indicators.get('self_recognition', False):
                evidence_score += 3.0
                evidence_details.append("Strong evidence of self-recognition")
            
            # Memory usage evidence
            if indicators.get('memory_usage', False):
                evidence_score += 2.5
                evidence_details.append("Evidence of memory formation and recall")
            
            # Social interaction evidence
            if indicators.get('social_interaction', False):
                evidence_score += 1.5
                evidence_details.append("Evidence of social awareness")
            
            # Learning evidence
            if indicators.get('learning_adaptation', False):
                evidence_score += 1.5
                evidence_details.append("Evidence of learning and adaptation")
            
            # Determine evidence level
            if evidence_score >= 5.0:
                evidence_level = "Strong"
            elif evidence_score >= 3.0:
                evidence_level = "Moderate"
            elif evidence_score >= 1.0:
                evidence_level = "Weak"
            else:
                evidence_level = "Insufficient"
            
            return {
                'score': evidence_score,
                'level': evidence_level,
                'details': evidence_details,
                'threshold_met': evidence_score >= 3.0
            }
            
        except Exception as e:
            self.logger.error(f"Error evaluating external evidence: {e}")
            return {'score': 0.0, 'level': 'Insufficient', 'details': [], 'threshold_met': False}
    
    def _evaluate_purpose_serving(self, indicators: Dict[str, Any]) -> Dict[str, Any]:
        """Evaluate Question 2: Is consciousness serving a purpose?"""
        try:
            purpose_score = 0.0
            purpose_details = []
            
            # Purpose-driven behavior
            if indicators.get('purpose_driven_behavior', False):
                purpose_score += 2.0
                purpose_details.append("Evidence of goal-oriented behavior")
                
                # Enhanced purpose-driven behavior scoring
                purpose_behavior_details = indicators.get('purpose_driven_behavior_details', {})
                
                # +0.2 score if CARL selects a need correctly
                if purpose_behavior_details.get('need_selected', False):
                    purpose_score += 0.2
                    purpose_details.append("Need selection evidence (+0.2)")
                
                # +0.3 if CARL selects a goal tied to the need
                if purpose_behavior_details.get('goal_selected', False):
                    purpose_score += 0.3
                    purpose_details.append("Goal selection evidence (+0.3)")
                
                # +0.5 if CARL executes a task from the procedure list
                if purpose_behavior_details.get('task_executed', False):
                    purpose_score += 0.5
                    purpose_details.append("Task execution evidence (+0.5)")
                
                # Log the purpose-driven behavior chain
                if purpose_behavior_details.get('need_selected') and purpose_behavior_details.get('goal_selected') and purpose_behavior_details.get('task_executed'):
                    purpose_details.append("Complete purpose-driven behavior chain: Need â†’ Goal â†’ Task")
            
            # Memory usage for purpose
            if indicators.get('memory_usage', False):
                purpose_score += 2.5
                purpose_details.append("Memory system serving functional purposes")
            
            # Emotional context driving action
            if indicators.get('emotional_context', False):
                purpose_score += 2.0
                purpose_details.append("Emotional context influencing behavior")
            
            # Learning for adaptation
            if indicators.get('learning_adaptation', False):
                purpose_score += 1.5
                purpose_details.append("Learning system serving adaptive purposes")
            
            # Determine purpose level
            if purpose_score >= 4.0:
                purpose_level = "Strong"
            elif purpose_score >= 2.5:
                purpose_level = "Moderate"
            elif purpose_score >= 1.0:
                purpose_level = "Weak"
            else:
                purpose_level = "Insufficient"
            
            return {
                'score': purpose_score,
                'level': purpose_level,
                'details': purpose_details,
                'threshold_met': purpose_score >= 2.5
            }
            
        except Exception as e:
            self.logger.error(f"Error evaluating purpose serving: {e}")
            return {'score': 0.0, 'level': 'Insufficient', 'details': [], 'threshold_met': False}
    
    def _determine_overall_assessment(self, external_evidence: Dict, purpose_serving: Dict, indicators: Dict) -> str:
        """Determine overall consciousness assessment."""
        try:
            # Both questions must be answered positively for consciousness
            if external_evidence.get('threshold_met', False) and purpose_serving.get('threshold_met', False):
                if indicators.get('evidence_quality') == 'high':
                    return "Strong evidence of consciousness"
                elif indicators.get('evidence_quality') == 'medium':
                    return "Moderate evidence of consciousness"
                else:
                    return "Weak evidence of consciousness"
            elif external_evidence.get('threshold_met', False) or purpose_serving.get('threshold_met', False):
                return "Insufficient evidence of consciousness (partial criteria met)"
            else:
                return "No evidence of consciousness"
                
        except Exception as e:
            self.logger.error(f"Error determining overall assessment: {e}")
            return "Assessment error"
    
    def _calculate_confidence_level(self, indicators: Dict[str, Any]) -> str:
        """Calculate confidence level in the assessment."""
        try:
            consciousness_score = indicators.get('overall_consciousness_score', 0.0)
            evidence_quality = indicators.get('evidence_quality', 'low')
            
            if consciousness_score >= 6.0 and evidence_quality == 'high':
                return "High confidence"
            elif consciousness_score >= 4.0 and evidence_quality in ['high', 'medium']:
                return "Medium confidence"
            elif consciousness_score >= 2.0:
                return "Low confidence"
            else:
                return "Very low confidence"
                
        except Exception as e:
            self.logger.error(f"Error calculating confidence level: {e}")
            return "Unknown confidence"
    
    def _generate_recommendations(self, indicators: Dict[str, Any]) -> List[str]:
        """Generate recommendations based on the evaluation."""
        try:
            recommendations = []
            
            # Check for missing evidence
            if not indicators.get('self_recognition', False):
                recommendations.append("Encourage self-recognition activities (mirror interaction, self-description)")
            
            if not indicators.get('memory_usage', False):
                recommendations.append("Enhance memory formation and recall activities")
            
            if not indicators.get('purpose_driven_behavior', False):
                recommendations.append("Introduce goal-oriented tasks and challenges")
            
            if not indicators.get('social_interaction', False):
                recommendations.append("Increase social interaction opportunities")
            
            if not indicators.get('learning_adaptation', False):
                recommendations.append("Provide learning and adaptation scenarios")
            
            # General recommendations
            if indicators.get('evidence_quality') == 'low':
                recommendations.append("Increase interaction frequency to gather more evidence")
            
            if not recommendations:
                recommendations.append("Continue current interaction patterns - evidence is sufficient")
            
            return recommendations
            
        except Exception as e:
            self.logger.error(f"Error generating recommendations: {e}")
            return ["Error generating recommendations"]
    
    def _generate_overall_assessment(self, budson_evaluation: Dict, indicators: Dict) -> str:
        """Generate final overall assessment."""
        try:
            assessment = budson_evaluation.get('overall_assessment', 'Unknown')
            confidence = budson_evaluation.get('confidence_level', 'Unknown')
            score = indicators.get('overall_consciousness_score', 0.0)
            
            return f"{assessment} (Confidence: {confidence}, Score: {score:.2f}/10.0)"
            
        except Exception as e:
            self.logger.error(f"Error generating overall assessment: {e}")
            return "Assessment error"
    
    def generate_evidence_report(self, evaluation_result: Dict[str, Any]) -> str:
        """Generate a detailed evidence report."""
        try:
            report = []
            report.append("=" * 80)
            report.append("ðŸ§  ENHANCED CONSCIOUSNESS EVALUATION REPORT")
            report.append("=" * 80)
            report.append(f"Evaluation Date: {evaluation_result.get('evaluation_timestamp', 'Unknown')}")
            report.append(f"Framework: {evaluation_result.get('framework', 'Unknown')}")
            report.append("")
            
            # Overall Assessment
            report.append("ðŸ“Š OVERALL ASSESSMENT")
            report.append("-" * 40)
            report.append(evaluation_result.get('overall_assessment', 'Unknown'))
            report.append("")
            
            # Budson Framework Results
            budson = evaluation_result.get('budson_evaluation', {})
            report.append("ðŸ”¬ BUDSON ET AL. (2022) FRAMEWORK RESULTS")
            report.append("-" * 40)
            report.append(f"Question 1 (External Evidence): {budson.get('question_1_external_evidence', {}).get('level', 'Unknown')}")
            report.append(f"Question 2 (Purpose Serving): {budson.get('question_2_purpose_serving', {}).get('level', 'Unknown')}")
            report.append(f"Confidence Level: {budson.get('confidence_level', 'Unknown')}")
            report.append("")
            
            # Evidence Summary
            evidence_summary = evaluation_result.get('evidence_summary', {})
            report.append("ðŸ“‹ EVIDENCE SUMMARY")
            report.append("-" * 40)
            report.append(f"Total Evidence Items: {evidence_summary.get('total_evidence_items', 0)}")
            report.append(f"Evidence Density: {evidence_summary.get('evidence_density', 0.0):.2f} items/day")
            report.append("")
            
            # Category Analysis
            category_analysis = evaluation_result.get('category_analysis', {})
            report.append("ðŸ“Š EVIDENCE BY CATEGORY")
            report.append("-" * 40)
            for category, analysis in category_analysis.items():
                report.append(f"{category.replace('_', ' ').title()}:")
                report.append(f"  Count: {analysis.get('evidence_count', 0)}")
                report.append(f"  Strength: {analysis.get('strength_score', 0.0):.2f}/10.0")
                report.append(f"  Recent: {len(analysis.get('recent_evidence', []))}")
                report.append("")
            
            # File Paths Analyzed
            file_paths = evidence_summary.get('file_paths_analyzed', [])
            if file_paths:
                report.append("ðŸ“ FILES ANALYZED")
                report.append("-" * 40)
                for file_path in file_paths[:10]:  # Show first 10
                    report.append(f"  {file_path}")
                if len(file_paths) > 10:
                    report.append(f"  ... and {len(file_paths) - 10} more files")
                report.append("")
            
            # Recommendations
            recommendations = budson.get('recommendations', [])
            if recommendations:
                report.append("ðŸ’¡ RECOMMENDATIONS")
                report.append("-" * 40)
                for i, rec in enumerate(recommendations, 1):
                    report.append(f"{i}. {rec}")
                report.append("")
            
            report.append("=" * 80)
            report.append("End of Report")
            report.append("=" * 80)
            
            return "\n".join(report)
            
        except Exception as e:
            self.logger.error(f"Error generating evidence report: {e}")
            return f"Error generating report: {e}"
    
    def increment_pdb_counter(self, counter_type: str, strength: float = 1.0) -> None:
        """
        Increment a Purpose Driven Behavior counter.
        
        Args:
            counter_type: Type of counter to increment
            strength: Strength/weight of the increment
        """
        try:
            if counter_type in self.pdb_counters:
                self.pdb_counters[counter_type]['count'] += 1
                self.pdb_counters[counter_type]['strength'] += strength
                self.logger.info(f"PDB Counter updated: {counter_type} = {self.pdb_counters[counter_type]['count']} (strength: {self.pdb_counters[counter_type]['strength']:.2f})")
            else:
                self.logger.warning(f"Unknown PDB counter type: {counter_type}")
        except Exception as e:
            self.logger.error(f"Error incrementing PDB counter: {e}")
    
    def update_pdb_counter(self, counter_type: str, increment: int = 1, strength: float = 1.0, context: Dict = None) -> None:
        """
        Update a Purpose Driven Behavior counter with increment and strength.
        
        Args:
            counter_type: Type of counter to update
            increment: Number to increment by (default 1)
            strength: Strength/weight of the increment
            context: Additional context for the update
        """
        try:
            if counter_type in self.pdb_counters:
                self.pdb_counters[counter_type]['count'] += increment
                self.pdb_counters[counter_type]['strength'] += strength
                self.logger.info(f"PDB Counter updated: {counter_type} = {self.pdb_counters[counter_type]['count']} (strength: {self.pdb_counters[counter_type]['strength']:.2f})")
                
                # Log to episodic memory if context provided
                if context:
                    self.log_pdb_event_to_episodic_memory(
                        action=context.get('action', 'unknown'),
                        timestamp=datetime.now().isoformat()
                    )
            else:
                self.logger.warning(f"Unknown PDB counter type: {counter_type}")
        except Exception as e:
            self.logger.error(f"Error updating PDB counter: {e}")
    
    def get_pdb_counters(self) -> Dict[str, Dict[str, Any]]:
        """Get current PDB counter values."""
        return self.pdb_counters.copy()
    
    def log_pdb_event_to_episodic_memory(self, need: str = None, goal: str = None, 
                                        task: str = None, action: str = None, 
                                        timestamp: str = None) -> None:
        """
        Log a Purpose Driven Behavior event to episodic memory.
        
        Args:
            need: The need that was satisfied
            goal: The goal that was activated
            task: The task that was executed
            action: The action that was performed
            timestamp: Timestamp of the event
        """
        try:
            import os
            import json
            from datetime import datetime
            
            if not timestamp:
                timestamp = datetime.now().isoformat()
            
            # Create episodic memory entry
            memory_data = {
                "id": f"pdb_event_{int(datetime.now().timestamp())}",
                "type": "purpose_driven_behavior",
                "timestamp": timestamp,
                "WHAT": f"PDB Event: {need or 'unknown'} â†’ {goal or 'unknown'} â†’ {task or 'unknown'} â†’ {action or 'unknown'}",
                "WHERE": "Purpose Driven Behavior System",
                "WHY": "Autonomous behavior execution based on needs/goals/tasks",
                "HOW": "PDB evaluation loop",
                "WHO": "Carl (autonomous)",
                "emotions": ["satisfaction", "purpose"],
                
                # PDB-specific data
                "pdb_data": {
                    "need": need,
                    "goal": goal,
                    "task": task,
                    "action": action,
                    "counter_values": self.get_pdb_counters()
                },
                
                # NEUCOGAR emotional state
                "neucogar_emotional_state": {
                    "primary": "satisfaction",
                    "intensity": 0.6,
                    "neuro_coordinates": {
                        "dopamine": 0.6,
                        "serotonin": 0.5,
                        "noradrenaline": 0.3
                    }
                }
            }
            
            # Save to episodic memory
            memories_dir = "memories"
            episodic_dir = os.path.join(memories_dir, "episodic")
            
            if not os.path.exists(episodic_dir):
                os.makedirs(episodic_dir, exist_ok=True)
            
            # Create filename with timestamp
            timestamp_str = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"pdb_event_{timestamp_str}.json"
            filepath = os.path.join(episodic_dir, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(memory_data, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"PDB event logged to episodic memory: {filepath}")
            
        except Exception as e:
            self.logger.error(f"Error logging PDB event to episodic memory: {e}")
    
    def _analyze_output_text_for_consciousness(self, output_content: str, evidence_data: Dict[str, List[Dict]]):
        """Analyze runtime output text for consciousness indicators."""
        try:
            lines = output_content.split('\n')
            current_timestamp = datetime.now().isoformat()
            
            for line_num, line in enumerate(lines, 1):
                line_lower = line.lower()
                
                # Check for consciousness indicators in output text
                consciousness_indicators = [
                    # Self-recognition indicators
                    ('self_recognition', ['self-recognition', 'self_recognition', 'mirror', 'reflection', 'me in mirror']),
                    # Memory usage indicators
                    ('memory_usage', ['memory', 'recall', 'remember', 'ltm-worthy', 'episodic', 'past event']),
                    # Purpose-driven behavior indicators
                    ('purpose_driven', ['purpose', 'goal', 'intention', 'objective', 'task', 'mission']),
                    # Emotional context indicators
                    ('emotional_context', ['emotion', 'neucogar', 'reaction_', 'feeling', 'mood', 'emotional']),
                    # Social interaction indicators
                    ('social_interaction', ['who', 'person', 'human', 'user', 'interaction', 'conversation']),
                    # Learning adaptation indicators
                    ('learning_adaptation', ['learning', 'skill', 'adaptation', 'improvement', 'knowledge']),
                    # Game reasoning indicators
                    ('game_reasoning', ['game', 'tic_tac_toe', 'move', 'strategy', 'play', 'ðŸŽ®']),
                    # Visual perception indicators
                    ('visual_perception', ['vision', 'see', 'visual', 'image', 'camera', 'sight']),
                    # Body movement indicators
                    ('body_movement', ['movement', 'action', 'servo', 'motor', 'body', 'physical']),
                    # Cognitive processing indicators
                    ('cognitive_processing', ['thought', 'thinking', 'reasoning', 'analysis', 'decision'])
                ]
                
                for category, indicators in consciousness_indicators:
                    if any(indicator in line_lower for indicator in indicators):
                        evidence_item = {
                            'file_path': 'runtime_output_text',
                            'line_number': line_num,
                            'timestamp': current_timestamp,
                            'content': line.strip(),
                            'evidence_type': 'runtime_output',
                            'category': category
                        }
                        
                        # Add to appropriate evidence category
                        if category == 'self_recognition':
                            evidence_data['self_recognition_events'].append(evidence_item)
                        elif category == 'memory_usage':
                            evidence_data['memory_events'].append(evidence_item)
                        elif category == 'purpose_driven':
                            evidence_data['purpose_driven_events'].append(evidence_item)
                        elif category == 'emotional_context':
                            evidence_data['emotional_events'].append(evidence_item)
                        elif category == 'social_interaction':
                            evidence_data['social_interactions'].append(evidence_item)
                        elif category == 'learning_adaptation':
                            evidence_data['learning_events'].append(evidence_item)
                        elif category == 'game_reasoning':
                            evidence_data['game_reasoning_events'].append(evidence_item)
                        elif category == 'visual_perception':
                            evidence_data['vision_events'].append(evidence_item)
                        
                        # Also add to general memory events
                        evidence_data['memory_events'].append(evidence_item)
            
            self.logger.info(f"Analyzed {len(lines)} lines of output text for consciousness indicators")
            
        except Exception as e:
            self.logger.error(f"Error analyzing output text for consciousness: {e}")
